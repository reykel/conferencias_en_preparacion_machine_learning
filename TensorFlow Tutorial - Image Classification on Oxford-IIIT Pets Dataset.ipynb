{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reykel/machine_learning_keras_tf/blob/main/TensorFlow%20Tutorial%20-%20Image%20Classification%20on%20Oxford-IIIT%20Pets%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5-w4D1gIF9S"
      },
      "source": [
        "# TensorFlow Tutorial - Transfer Learning for Multi-Class Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x51PXnTLIF9Z"
      },
      "source": [
        "### Step-by-step guide to using the pre-trained ResNet50 V2 model for image classification of Oxford-IIIT Pets dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIxyCxlLIF9a"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72ztNMj8KOO0"
      },
      "source": [
        "## (1) Initial Setup\n",
        "- Highly recommended to run this notebook in Google Colab\n",
        "- All the essential Python libraries we need for this project are already pre-installed in the default Google Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCPyQZ1Yea_a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiuR153P65-P"
      },
      "outputs": [],
      "source": [
        "# Check Tensorflow version\n",
        "tf. __version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_MRrw_satLX"
      },
      "source": [
        "___\n",
        "## (2) Import Data\n",
        "- For this project, we will be working with the Oxford-IIIT dataset (https://www.robots.ox.ac.uk/~vgg/data/pets/)\n",
        "- The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200 images for each class. The images have large variations in scale, pose and lighting. All images have an associated ground truth annotation of breed.\n",
        "- While there are various sources where the image dataset can be downloaded from, we will use the `tfds` module to load the images. \n",
        "- `tfds` stands for Tensorflow Datasets, and it is a Tensorflow component that defines a collection of datasets ready-to-use with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YoxdqdIIF9h"
      },
      "source": [
        "#### Load and split the raw image data\n",
        "- We load the pets dataset (named as `oxford_iiit_pet` in `tfds`) as a `tf.data.Dataset` object, and the raw dataset has two sets: train and test\n",
        "- For our project, we want to split the dataset into three sets: train set, validation set, and test set. \n",
        "- The train/val split is set as 90:10 ratio, and we also ensure the images are shuffled\n",
        "- We can use percentages (%) to slice the datasets, so that there is no need for us to input the exact index for splitting\n",
        "- Note that when we set the parameter `with_info=True`, we will also obtain the dataset documentation along with the images. \n",
        "- This dataset documentation (which we save as `ds_info`) contains a host of information, but perhaps the most important one is the label name (i.e. pet breed) for each image class\n",
        "- The output will be captured as a tuple: (image datasets, dataset information) when we set `as_supervised=True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlC7eEuq_Dmd"
      },
      "outputs": [],
      "source": [
        "(train_raw, val_raw, test_raw), ds_info = tfds.load(name='oxford_iiit_pet',\n",
        "                                                    split=['train[:90%]', \n",
        "                                                          'train[90%:]', \n",
        "                                                          'test'],\n",
        "                                                    shuffle_files=True,\n",
        "                                                    as_supervised=True, # Returns (image, label)\n",
        "                                                    with_info=True # To retrieve dataset info and label names\n",
        "                                                    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7k0UWugIF9j"
      },
      "source": [
        "ðŸ’¬ **Checkpoint**\n",
        "- Earlier we made use of the Tensorflow component called Tensorflow Datasets (`tfds`) to load a pre-saved dataset\n",
        "- If we have custom datasets (e.g., CSV files) that we want to load into `tfds`, refer to the following guides:\n",
        "    - https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnR5e-yNpGLq"
      },
      "outputs": [],
      "source": [
        "ds_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QwFUztwIF9l"
      },
      "source": [
        "### Display several examples of the image dataset (from the train set) using the in-built `tfds.show_examples` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2enSNkCGTYTK"
      },
      "outputs": [],
      "source": [
        "tfds.show_examples(train_raw, ds_info, image_key='image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7WGvz8vIF9m"
      },
      "source": [
        "___\n",
        "## (3) Understanding the dataset\n",
        "#### Retrieve relevant counts to better understand the dataset we will be working on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuzS09oqh_CL"
      },
      "outputs": [],
      "source": [
        "# Get number of classes\n",
        "num_classes = ds_info.features['label'].num_classes\n",
        "print('Number of classes:', num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Py5plHU-XLP"
      },
      "outputs": [],
      "source": [
        "num_train_examples = tf.data.experimental.cardinality(train_raw).numpy()\n",
        "num_val_examples = tf.data.experimental.cardinality(val_raw).numpy()\n",
        "num_test_examples = tf.data.experimental.cardinality(test_raw).numpy()\n",
        "\n",
        "print('Number of training samples:', num_train_examples)\n",
        "print('Number of validation samples:', num_val_examples)\n",
        "print('Number of test samples:', num_test_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzbeOKnXr8vC"
      },
      "outputs": [],
      "source": [
        "def get_value_counts(ds):\n",
        "    label_list = []\n",
        "    for images, labels in ds: \n",
        "        label_list.append(labels.numpy())\n",
        "    label_counts = pd.Series(label_list).value_counts(sort=True)\n",
        "\n",
        "    print(label_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xawpyYKrTy-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "get_value_counts(train_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlaBDPxXtHot",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "get_value_counts(val_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjlWIIk48Q05"
      },
      "outputs": [],
      "source": [
        "# Function to obtain the name for the label integer\n",
        "get_label_name = ds_info.features['label'].int2str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrtJC6cU8S1P"
      },
      "outputs": [],
      "source": [
        "# Build the custom function to display image and label name\n",
        "def view_single_image(ds):\n",
        "    image, label = next(iter(ds))\n",
        "    print('Image shape: ', image.shape)\n",
        "    plt.imshow(image)\n",
        "    _ = plt.title(get_label_name(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZKIxuF08SzL"
      },
      "outputs": [],
      "source": [
        "view_single_image(train_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtQNxS1wGrt1"
      },
      "source": [
        "___\n",
        "## (4) Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZMwvhKmIF9r"
      },
      "source": [
        "### (i) Image Resizing\n",
        "- Because the raw images come in different sizes, we want to resize them to the same size before parsing them into the neural network later\n",
        "- More specifically, we want both the length and width to be 224 pixels (which is what ResNet50 expects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flZR84vP79G0"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "train_ds = train_raw.map(lambda x, y: (tf.image.resize(x, (IMG_SIZE, IMG_SIZE)), y))\n",
        "val_ds = val_raw.map(lambda x, y: (tf.image.resize(x, (IMG_SIZE, IMG_SIZE)), y))\n",
        "test_ds = test_raw.map(lambda x, y: (tf.image.resize(x, (IMG_SIZE, IMG_SIZE)), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE938XREIF9r"
      },
      "source": [
        "___\n",
        "### (ii) Label One-hot Encoding\n",
        "- There are 37 classes (i.e. pet breeds) in the dataset that we are using for multi-class image classification\n",
        "- As such, we proceed to one-hot encode the labels so that we get a output vector of length 37"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85QnAWPwhUAY"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(image, label):\n",
        "    label = tf.one_hot(label, num_classes)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kunr83I4hIqW"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(one_hot_encode)\n",
        "val_ds = val_ds.map(one_hot_encode)\n",
        "test_ds = test_ds.map(one_hot_encode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu9fzhA-IF9u"
      },
      "source": [
        "#### Let's have a look at what our dataset object looks like currently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg5S_ehs79EP"
      },
      "outputs": [],
      "source": [
        "train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvrMwAD-IF9v"
      },
      "source": [
        "From the printout, we can see that each dataset object (i.e., `train_ds`, `val_ds`, and `test_ds`) has two components each:\n",
        "- Images of shape (224,224,3) \n",
        "- Label vector of shape (37,)\n",
        "\n",
        "The values in each component has also been casted to a float data type, which is what we want for the deep learning model later. Another point to keep in mind is that these objects are **generators**, meaning that they only return one set of image and label when we iterate over it one value at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53_1oYCjIF9w"
      },
      "source": [
        "### (iii) Image (Data) Augmentation\n",
        "- Image augmentation artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc.\n",
        "- The purpose is to reduce model overfitting by exposing our model to variations and small transformations in the original data. It is useful especially when we do not have a large dataset.\n",
        "- Note that the image augmentation needs to be realistic. For example, flipping car images upside down may not be the best choice here since we expect most cars to be photographed with the wheels on the ground (barring severe accidents)\n",
        "- To perform data augmentation, we use the Keras preprocessing layers API. Each type of image augmentation that we want to introduce is defined as a layer within a Keras Sequential class.\n",
        "- We will only perform a random horizontal flip for the images for the sake of simplicity, though do note that there is a wide range of different augmentations available to us: https://keras.io/api/layers/preprocessing_layers/image_augmentation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1DmEwWt78_h"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomFlip('horizontal'), \n",
        "    layers.RandomRotation(factor=(-0.025, 0.025)),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomContrast(factor=0.1),\n",
        "     ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY8Z4Fanl8Ol"
      },
      "source": [
        "#### View effects of augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CzyZmUkjgSI"
      },
      "outputs": [],
      "source": [
        "for image, label in train_ds.take(1):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(4):\n",
        "        ax = plt.subplot(2, 2, i+1)\n",
        "        aug_img = data_augmentation(tf.expand_dims(image, axis=0))\n",
        "        plt.imshow(aug_img[0].numpy().astype(\"uint8\"))\n",
        "        plt.title(get_label_name(int(label[0])))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SCbHpG5IF9x"
      },
      "source": [
        "### (iv) Batching and Prefetching\n",
        "- We can batch the data and use prefetching to optimize loading speed and model efficiency\n",
        "- A batch size of 32 is a good value to start with\n",
        "- The number of elements to prefetch can be automatically determined by making use of `tf.data.AUTOTUNE`, which prompt the runtime to tune the value dynamically for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqswYjuVeijU"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx8Jmqlwi2xE"
      },
      "outputs": [],
      "source": [
        "# Batch the data and use prefetching to optimize loading speed\n",
        "# AVOID use of caching (Google Colab RAM limits)\n",
        "\n",
        "train_ds = train_ds.batch(batch_size=BATCH_SIZE, \n",
        "                          drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = val_ds.batch(batch_size=BATCH_SIZE, \n",
        "                      drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "                      \n",
        "test_ds = test_ds.batch(batch_size=BATCH_SIZE, \n",
        "                        drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytBFBhs-nV8s"
      },
      "source": [
        "- After batching and prefetching, note that the dataset object has been transformed such that the earlier functions to view images will no longer work\n",
        "- Caching (with `.cache()`) is another way to speed up the process, where we store dataset either in memory or on local storage. This will save some operations (like file opening and data reading) from being executed during each epoch. However, note that this can cause RAM limit issues in the free version of Google Colab, thus caching has been excluded in this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLmCCHF0IF9y"
      },
      "source": [
        "___\n",
        "## (5) Model Setup\n",
        "- With the data prepared, it is time to define the model we want to use for the multi-class classification task\n",
        "- For this task, we will make use of transfer learning so that we do not need to train a deep learning model from scratch (which is tedious and requires plenty of data)\n",
        "- Keras comes with a host of pre-trained models that we can leverage for transfer learning: https://keras.io/api/applications/\n",
        "- We will be using ResNet50V2 given that it offers a good balance of accuracy, size, and speed\n",
        "- More information about ResNet can be found here: https://keras.io/api/applications/resnet/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1vZ1CkSIF9y"
      },
      "source": [
        "### (i) Setup base model\n",
        "- Instantiate a ResNet50V2 object from `keras.applications`\n",
        "- Set `include_top=False` because we want to remove the top layers of the pre-trained model (that was trained to classify ImageNet) and introduce our own final layers for our specific car image classification task\n",
        "- Keep the weights as `imagenet`, because we want to keep the ResNet weights that were trained on the ImageNet dataset\n",
        "- This process is known as transfer learning, because we use the pre-trained ImageNet weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mGv0YTRkAuh"
      },
      "outputs": [],
      "source": [
        "base_model = keras.applications.ResNet50V2(\n",
        "                            include_top=False, # Exclude ImageNet classifier at the top.\n",
        "                            weights=\"imagenet\",\n",
        "                            input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        "                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4BUx3qtIF9z"
      },
      "source": [
        "### (ii) Freeze pre-trained weights of the base model\n",
        "- When a trainable weight becomes non-trainable, its value is no longer updated during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQstp9NJLsH5"
      },
      "outputs": [],
      "source": [
        "# Freeze the base_model\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krBHgPqBIF90"
      },
      "source": [
        "### (iii) Modify inputs\n",
        "- We pre-process the inputs (i.e., images) so that they are compatible with what the pre-trained ResNet50v2 architecture expects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEL0fm4MMyAT"
      },
      "outputs": [],
      "source": [
        "# Create new model on top\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il17gP6GC6eS"
      },
      "outputs": [],
      "source": [
        "x = keras.applications.resnet_v2.preprocess_input(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG6MvY0ZfikL"
      },
      "outputs": [],
      "source": [
        "x = base_model(x, training=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU_kUbr9IF91"
      },
      "source": [
        "- Although the base model becomes trainable, it is still running in inference mode since we passed `training=False` when calling it when we built the model.\n",
        "- This means that the batch normalization layers inside will not update their batch statistics (i.e., mean and variance)\n",
        "- If they did, they would wreak havoc on the representations learned by the model so far because the training done would have been undone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac7rWRP7IF91"
      },
      "source": [
        "### (iv) Rebuild top layers\n",
        "- Given that we have removed the top ImageNet classifier layer of ResNet50V2, we can now build a custom top layer that is specific to our image classification task i.e., classify an image based on the 37 different pet breeds types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Bhctp_lDf7O"
      },
      "outputs": [],
      "source": [
        "# Rebuild top layers\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7oTpXa2IF92"
      },
      "source": [
        "#### Display model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFvnJ0PHMx5F"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lQH8Zi9IF92"
      },
      "source": [
        "#### Compile model\n",
        "- Utilize the commonly used Adam optimizer (leave the learning rate as default)\n",
        "- Since it is a multi-class classification, we will use categorical cross entropy and categorical accuracy as our loss and performance metric respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szzwqavGm-eT"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()]\n",
        "             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke4TR1jfIF93"
      },
      "source": [
        "#### Include early stopping\n",
        "- Prevent overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDeoK30OcB3w"
      },
      "outputs": [],
      "source": [
        "earlystopping = callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                        mode='min', \n",
        "                                        patience=3, \n",
        "                                        restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo0s0c_8IF93"
      },
      "source": [
        "___\n",
        "## (6) Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoSyBDreIF94"
      },
      "source": [
        "#### Fit model\n",
        "- Ensure that the Google Colab runtime using GPU hardware accelerator\n",
        "- Fit the model over the training dataset for 15 epochs\n",
        "- Store the training output as a variable called `history`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90lrUy83_vQi"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 25\n",
        "\n",
        "history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, verbose=2,\n",
        "                    callbacks =[earlystopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcjp2eiFIF95"
      },
      "source": [
        "#### Plot the accuracy of training and validation sets over epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le4bTgZRyJrb"
      },
      "outputs": [],
      "source": [
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history['categorical_accuracy'])\n",
        "    plt.plot(hist.history['val_categorical_accuracy'])\n",
        "    plt.title('Categorical accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plot_hist(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsvR80S2IF95"
      },
      "source": [
        "___\n",
        "## (7) Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLwinPkfoJ1v"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmUK2VkOIF96"
      },
      "source": [
        "#### Evaluate model on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7lWIPk_jy5b"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHrND8GHIF99"
      },
      "source": [
        "#### Display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wneg7O6bsFuy"
      },
      "outputs": [],
      "source": [
        "dict(zip(model.metrics_names, result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZqbPYgfHmFp"
      },
      "source": [
        "___\n",
        "## (8) Finetune Model (OPTIONAL)\n",
        "- Once our model has converged on the new data, we can try to unfreeze all or part of the base model and retrain the whole model end-to-end with a very low learning rate (e.g., 0.0001)\n",
        "- This is an optional last step that can potentially give us incremental improvements. However, it can also potentially lead to quick overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsqvVJTXIF9-"
      },
      "source": [
        "#### Unfreeze base model\n",
        "- We only want to unfreeze top 15 layers that are NOT batch normalization layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYxiOONHjyvs"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers[-15:]:\n",
        "    if not isinstance(layer, layers.BatchNormalization):\n",
        "        layer.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlZCEYh4IF9-"
      },
      "source": [
        "#### Recompile model\n",
        "- This step needs to be done to take into account the change above, where we set the `trainable` attribute of the base model layers to True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhtw16HfjytK"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5), # Set a very low learning rate\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()]\n",
        "             )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16ELUU_-IF9_"
      },
      "source": [
        "#### Retrain model\n",
        "- Using fewer epochs given the high risk of overfitting in fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pskK5Llcd5MI"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "history_2 = model.fit(train_ds, \n",
        "                      epochs=EPOCHS, \n",
        "                      validation_data=val_ds, \n",
        "                      verbose=1,\n",
        "                      callbacks =[earlystopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDgK2BpSIF-A"
      },
      "source": [
        "#### Display fine-tuned model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv94w81eHqH-"
      },
      "outputs": [],
      "source": [
        "result_2 = model.evaluate(test_ds)\n",
        "\n",
        "dict(zip(model.metrics_names, result_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX_fHuPUQNqn"
      },
      "source": [
        "We can see that the final step of unfreezing several layers of the model has indeed given the model performance a good boost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnPhBi9gIF-A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}